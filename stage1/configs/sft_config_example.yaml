model_name_or_path: /path/to/Qwen2.5-Coder-0.5B
stage: sft
do_train: true
finetuning_type: lora
template: qwen

dataset_dir: stage1/data/sft_dataset
dataset: train

output_dir: stage1/outputs/sft
overwrite_output_dir: true

max_seq_length: 2048
learning_rate: 0.0002
num_train_epochs: 2
per_device_train_batch_size: 1
gradient_accumulation_steps: 16
logging_steps: 10
save_steps: 200

